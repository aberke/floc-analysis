{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd784eb6",
   "metadata": {},
   "source": [
    "# Sensivity by race by domain visit frequencies\n",
    "\n",
    "Questions we ask here:\n",
    "\n",
    "- Are there demographic (by race) differences in browsing behavior?\n",
    "\n",
    "t-closeness is one way of examining sensitivity.\n",
    "\n",
    "Here we look at sensitivity by race based on overall domain visitation frequency.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b795b652",
   "metadata": {},
   "source": [
    "chi-sq test of homogeneity: How we do it.\n",
    "\n",
    "we have r populations: {white, black, asian, other}\n",
    "\n",
    "preprocessing:\n",
    "use raw sessions data after removing bad domains\n",
    "\n",
    "make map \n",
    "\n",
    "{ machine_id: {domain: visits for each domain visited by machine} }\n",
    "\n",
    "over all 52 weeks of data\n",
    "\n",
    "table:\n",
    "\n",
    "```\n",
    "machine_id, domain, visits\n",
    "```\n",
    "\n",
    "where machine_id is duplicated for each domain the machine visited.\n",
    "\n",
    "\n",
    "\n",
    "our category is domain.\n",
    "\n",
    "we have D levels of our category, where D is the threshold number of most frequently visited domains.\n",
    "\n",
    "\n",
    "if we didn't use panel data\n",
    "\n",
    "Total sample is the size of our comscore data samples total: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6dd4734",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "from comscore.data import read_weeks_machines_domains, read_comscore_demo_df\n",
    "\n",
    "TOP_N_DOMAINS = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11688cb7",
   "metadata": {},
   "source": [
    "A core question left unanswered by our analysis of FLoC's sensitivity is whether racial groups in our dataset exhibit significant browsing behavior differences. If users' browsing history does not vary by racial group, then we should expect any clustering algorithm, including FLoC, to group independently of race. We use a Chi-Squared homogeneity test to test if racial groups' browsing behaviors are independent from race, treating each racial group as a separate population, and the top domains visited in our dataset as the categorical variable of interest. To calculate domain visit frequencies, we construct a set $D_w^m$ consisting of each unique domain visited by a machine $m$ in a given week $w$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59607f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading from ../output/weeks_machines_domains.csv...\n",
      "... read 4877236 rows\n"
     ]
    }
   ],
   "source": [
    "# read in the pre-processed sessions data \n",
    "# this maps week,machine_id -> domains set\n",
    "weeks_machines_domains_fpath = '../output/weeks_machines_domains.csv'\n",
    "weeks_machines_domains_df = read_weeks_machines_domains(weeks_machines_domains_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33ccdee1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "comscore_demo_df = (read_comscore_demo_df(fpath=\"../data/comscore/2017/demographics.csv\", year=2017)\n",
    "           .assign(machine_id=lambda x: x.machine_id.astype(int))\n",
    "          )\n",
    "\n",
    "df = (weeks_machines_domains_df.merge(comscore_demo_df, \n",
    "               how='inner', # only include machine_ids with valid data (no nan race)\n",
    "               left_on='machine_id', \n",
    "               right_on='machine_id')\n",
    "      .query(\"n_domains > 0\")\n",
    "     )\n",
    "# convert to list\n",
    "df.domains = [list(d) for d in df.domains]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d23d7104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate frequencies for each race group\n",
    "# takes a couple mins on my mac mini\n",
    "freqs = []\n",
    "for race in df.racial_background.unique():\n",
    "    df2 = df[df.racial_background == race]\n",
    "    counter = pd.Series(Counter(chain.from_iterable(df2.domains)))\n",
    "    freqs.append(counter)\n",
    "    \n",
    "races = df.racial_background.unique()\n",
    "dfs = [(pd.DataFrame(distribution)\n",
    "       .assign(race=races[i])) for i, distribution in enumerate(freqs)]\n",
    "\n",
    "for dist_df in dfs:\n",
    "    # '0' is the count column, for now.\n",
    "    dist_df['p'] = dist_df[0] / sum(dist_df[0])\n",
    "    dist_df['count'] = dist_df[0]\n",
    "    dist_df = dist_df.drop(0, axis=1)\n",
    "    \n",
    "# domain, count, p, race\n",
    "race_distributions = (pd.concat(dfs)\n",
    "                      .drop(0, axis=1)\n",
    "                      .reset_index()\n",
    "                      .rename({'index': 'domain'}, axis=1)\n",
    "                     )\n",
    "\n",
    "# stack and compute for all\n",
    "# domain, count, freq\n",
    "all_distribution = (race_distributions\n",
    " .drop(['race', 'p'], axis=1)\n",
    " .groupby('domain')\n",
    " .aggregate({'count': sum})\n",
    " .assign(p=lambda x: x['count'] / x['count'].sum())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a5ebcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top N domains overall\n",
    "top_domains = all_distribution.nlargest(TOP_N_DOMAINS, columns='p')\n",
    "top_domains['p'] = top_domains['count'] / top_domains['count'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e02d7d",
   "metadata": {},
   "source": [
    "Aggregating across weeks for each racial group, this gives us a distribution over all domains in our dataset. For example, here are the top 5 domains visited by each racial group in the comscore data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfdc86b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(race_distributions\n",
    " .groupby('race')\n",
    " .apply(lambda x: x.nlargest(5, columns='p'))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a732eb29",
   "metadata": {},
   "source": [
    "To calculate our Chi-Square statistics, we limit our analysis to the top 50 domains across all racial groups. Our contingency table consists of each domain as a \"category\" and each racial group as a separate population:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45a04e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chisquare, chi2_contingency\n",
    "\n",
    "race_dist_df = race_distributions[race_distributions.domain.isin(top_domains.index)]\n",
    "\n",
    "race_X = (race_dist_df\n",
    " [['domain', 'race', 'count']]\n",
    " .pivot(index='domain', columns='race')\n",
    "          # calc frequencies\n",
    ")\n",
    "race_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24cf0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't need this\n",
    "# expected_X = top_domains.count\n",
    "exp_stat, exp_p, dof, e = chi2_contingency(race_X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4544d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp_stat, exp_p, dof, e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a96cda9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1362a9b2",
   "metadata": {},
   "source": [
    "While the Chi-Square test demonstrates that there *is* a difference in browsing behavior between racial groups, it doesn't show the degree of that difference. To get a sense for differences in behavior, two plots displaying distributions over domain frequencies are below. The first is grouped, which gives a better sense of overall domains, and the second is faceted, which provides a sense of the actual differences in shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b0091c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotnine import (ggplot, geom_point, aes, stat_smooth, \n",
    "                      facet_wrap, geom_bar, element_text, \n",
    "                      theme, theme_minimal, labs, element_blank)\n",
    "\n",
    "(race_dist_df\n",
    " .assign(race=lambda x: pd.Categorical(x.race, categories=x.race.unique().sort()),\n",
    "        domain=lambda x: pd.Categorical(x.domain, categories=x.domain.unique()),)\n",
    " .pipe(lambda x:\n",
    "     ggplot(x, aes(x='reorder(domain, -p)', y='p', fill='race')) +\n",
    "     geom_bar(stat='identity', position='dodge') +\n",
    "     theme_minimal() +\n",
    "     theme(axis_text_x=element_text(angle=90, vjust=1, hjust=1)) +\n",
    "     labs(x=\"Domain\", y=\"Freq\", fill=\"Race\")\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1db497",
   "metadata": {},
   "outputs": [],
   "source": [
    "(race_dist_df\n",
    " .assign(race=lambda x: pd.Categorical(x.race, categories=x.race.unique().sort()),\n",
    "        domain=lambda x: pd.Categorical(x.domain, categories=x.domain.unique()),)\n",
    " .pipe(lambda x:\n",
    "     ggplot(x, aes(x='reorder(domain, -p)', y='p')) +\n",
    "     geom_bar(stat='identity', position='dodge') +\n",
    "     theme_minimal() +\n",
    "     theme(axis_text_x=element_blank()) +\n",
    "     labs(x=\"Domain\", y=\"Freq\") +\n",
    "       facet_wrap('~race')\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dc30ab",
   "metadata": {},
   "source": [
    "Although the distributions are generally shaped similarly, there are significant differences in overall frequencies to the top few sites overall."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
