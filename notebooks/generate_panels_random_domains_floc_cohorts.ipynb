{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "099e5eda",
   "metadata": {},
   "source": [
    "# FLoC cohorts from randomly assigning domains to panel samples\n",
    "\n",
    "Here we create a comparison/counterfactual to the true panel data.\n",
    "\n",
    "The same machine_ids for panels are used as for the true data, but where only the sample's demographics are kept.\n",
    "\n",
    "The visited sets of domains are randomly assigned to panel samples, but where domains are assigned in a way proportional to how they occur in the real panel data.\n",
    "\n",
    "With this creation, domain visits and therefore cohorts should not be correlated with demographics.\n",
    "\n",
    "\n",
    "Here's how we do this:\n",
    "\n",
    "- first take the real panel data, where panel samples are joined with their true sessions data, and data is then limited to samples with >= 7 domains per sample.\n",
    "\n",
    "- take the distribution of n_domains \n",
    "\n",
    "- take the distribution of domains, using each domain's frequency of occurance in the real samples.\n",
    "i.e. when domains are randomly sampled, their sampling weight is proportional to the number of samples for which they occur in the real panel data.\n",
    "\n",
    "Create fake panel data where\n",
    "- each machine,week sample from the real panel is assigned a set of domains by randomly sampling from the distribution of n_domains and the distribution of domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e173f73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import floc\n",
    "\n",
    "from comscore.data import read_weeks_machines_domains\n",
    "import prefixLSH\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137b6eb5",
   "metadata": {},
   "source": [
    "Read in the sessions data and join with the panel data as and make the distributions to randomly sample the fake panel data from:\n",
    "- n_domains distribution\n",
    "- domains distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23620667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading from ../output/weeks_machines_domains.csv...\n"
     ]
    }
   ],
   "source": [
    "# read in the pre-processed sessions data \n",
    "# this maps week,machine_id -> domains set\n",
    "weeks_machines_domains_fpath = '../output/weeks_machines_domains.csv'\n",
    "weeks_machines_domains_df = read_weeks_machines_domains(weeks_machines_domains_fpath)\n",
    "weeks_machines_domains_df.drop(['machine_id', 'domains'], axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d921e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_panels_fpath = '../output/all_panels.csv'\n",
    "all_panels_df = pd.read_csv(all_panels_fpath)\n",
    "print('read in all panels: %s total rows' % len(all_panels_df))\n",
    "print('%s panels' % all_panels_df.panel_id.nunique())\n",
    "all_panels_df.drop(['machine_id'], axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d8ef13",
   "metadata": {},
   "outputs": [],
   "source": [
    "weeks_machines_domains = weeks_machines_domains_df.set_index(['machine_id','week'])['domains']\n",
    "all_panels_df['domains'] = all_panels_df.set_index(['machine_id','week']).index.map(weeks_machines_domains)\n",
    "all_panels_df.drop(['machine_id','domains'], axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23acf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_domains_distribution = all_panels_df.n_domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786aee8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make map for domains distribution\n",
    "# map: {domain: frequency}\n",
    "\n",
    "# make a list of all domains where the frequency they appear in the list\n",
    "# is the same as the frequency which they appear in the panel samples\n",
    "# weekly domains sets\n",
    "domains_sets = all_panels_df.domains.to_list()\n",
    "good_domains = [d for domains in domains_sets for d in domains]\n",
    "# check this matches the n_domains distribution data\n",
    "assert(len(good_domains) == n_domains_distribution.sum())\n",
    "# transform that list into the map: {domain: frequency}\n",
    "domains_distribution_map = {d: 0 for d in set(good_domains)}\n",
    "print('%s unique domains' % len(domains_distribution_map))\n",
    "for d in good_domains:\n",
    "    domains_distribution_map[d] += 1\n",
    "# and then trandform this into 2 series:\n",
    "# domains_list has an item for each domain\n",
    "# and domains_p is a list of corresponding the probabilities (weights) \n",
    "# for each domain in domains_p where the indices match\n",
    "domains_list = list(domains_distribution_map.keys())\n",
    "domains_p = [v/len(good_domains) for v in domains_distribution_map.values()]\n",
    "assert(round((sum(domains_p)), 4) == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3a11a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "\n",
    "def get_random_domains_list(x):\n",
    "    n_domains = np.random.choice(n_domains_distribution, size=1)[0]\n",
    "    return set(np.random.choice(\n",
    "        domains_list,\n",
    "        size=n_domains,\n",
    "        replace=False, \n",
    "        p=domains_p\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37bd9c9",
   "metadata": {},
   "source": [
    "Create alternative version of panel by copying true panel and reassigning domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccdbf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_panels_random_domains_df = all_panels_df.copy().drop(\n",
    "    ['n_domains', 'domains'], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b6f300",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_panels_random_domains_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "019f9785",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wt/5pyhsskj1hgdzv_4hb1gpkpm0000gn/T/ipykernel_97588/3786121668.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_panels_random_domains_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'domains'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_panels_random_domains_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_random_domains_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mall_panels_random_domains_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_domains'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_panels_random_domains_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomains\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mall_panels_random_domains_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/floc-analysis/venv/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   8738\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8739\u001b[0m         )\n\u001b[0;32m-> 8740\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8742\u001b[0m     def applymap(\n",
      "\u001b[0;32m~/projects/floc-analysis/venv/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/floc-analysis/venv/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/floc-analysis/venv/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    826\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/wt/5pyhsskj1hgdzv_4hb1gpkpm0000gn/T/ipykernel_97588/2621506292.py\u001b[0m in \u001b[0;36mget_random_domains_list\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_domains\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdomains_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     ))\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_panels_random_domains_df['domains'] = all_panels_random_domains_df.apply(get_random_domains_list, axis=1)\n",
    "all_panels_random_domains_df['n_domains'] = all_panels_random_domains_df.domains.apply(len)\n",
    "all_panels_random_domains_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b160f2",
   "metadata": {},
   "source": [
    "Check the distributions of domains for the true vs randomly assigned data. Distributions should be similar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b775f2f6",
   "metadata": {},
   "source": [
    "From true data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "270b9395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "google.com        2069410\n",
       "yahoo.com         1343049\n",
       "bing.com          1303117\n",
       "facebook.com      1301940\n",
       "msn.com           1281952\n",
       "youtube.com       1089638\n",
       "live.com           933177\n",
       "amazon.com         898409\n",
       "ebay.com           375022\n",
       "wikipedia.org      325491\n",
       "aol.com            309125\n",
       "microsoft.com      305610\n",
       "pornhub.com        297105\n",
       "paypal.com         267934\n",
       "247-inc.net        266388\n",
       "pinterest.com      251874\n",
       "craigslist.org     251167\n",
       "walmart.com        247218\n",
       "netflix.com        242238\n",
       "twitter.com        210164\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_domains_value_counts = pd.Series(good_domains).value_counts()\n",
    "good_domains_value_counts.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdc80ae",
   "metadata": {},
   "source": [
    "From randomly assigned domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8193a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "panels_random_domains_value_counts = all_panels_random_domains_df['domains'].value_counts().head(20)\n",
    "panels_random_domains_value_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d31145e",
   "metadata": {},
   "source": [
    "Compute simhash on domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25b6be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply simhash\n",
    "all_panels_random_domains_df['simhash'] = all_panels_random_domains_df.domains.apply(floc.hashes.sim_hash_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f174924",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_panels_random_domains_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d41f385",
   "metadata": {},
   "source": [
    "##### Pre-compute cohorts for each panel\n",
    "\n",
    "each sample's cohort is dependent on the rest of the simhashes in the panel\n",
    "\n",
    "for this reason, cohorts must be computed per panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64854a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_k = 40 \n",
    "# preset all cohorts to None\n",
    "all_panels_random_domains_df['cohort'] = np.nan\n",
    "\n",
    "for panel_id in all_panels_random_domains_df.panel_id.unique():\n",
    "    t_start = datetime.now()\n",
    "    if panel_id % 1 == 0:\n",
    "        print('computing cohorts for panel %s/%s' % (panel_id, all_panels_random_domains_df.panel_id.nunique()))\n",
    "    panel_df = all_panels_random_domains_df[all_panels_random_domains_df.panel_id==panel_id]\n",
    "    cohorts_dict = prefixLSH.get_cohorts_dict(panel_df.simhash.astype(int), min_k=min_k)\n",
    "    assign_cohort = lambda x: cohorts_dict[x.simhash] if x.panel_id == panel_id else x['cohort']\n",
    "    all_panels_random_domains_df['cohort'] = all_panels_random_domains_df.apply(assign_cohort, axis=1)\n",
    "    if panel_id % 1 == 0:\n",
    "        print('took %s' % (datetime.now() - t_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61919b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_panels_random_domains_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0a3202",
   "metadata": {},
   "source": [
    "save output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48224def",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_panels_random_domains_cohorts_fpath = '../output/all_panels_random_domains_cohorts.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7509d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('saving to %s...' % all_panels_random_domains_cohorts_fpath)\n",
    "all_panels_random_domains_df.to_csv(all_panels_random_domains_cohorts_fpath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96c223d",
   "metadata": {},
   "source": [
    "script re-entry point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47eb919",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_panels_random_domains_df = pd.read_csv(all_panels_random_domains_cohorts_fpath)\n",
    "print('read in all panels: %s total rows' % len(all_panels_random_domains_df))\n",
    "print('%s panels' % all_panels_random_domains.panel_id.nunique())\n",
    "all_panels_random_domains_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbe57c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
